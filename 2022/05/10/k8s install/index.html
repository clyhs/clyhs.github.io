<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">



<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css">


  <meta name="keywords" content="k8s,">





  <link rel="alternate" href="/atom.xml" title="大鱼的博客" type="application/atom+xml">




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0">






<meta name="description" content="k8s install Kubernetes Cluster = N Master Node + N Worker Node：N主节点+N工作节点； N&amp;gt;=1  ready servercentos7 64  master 192.168.2.221 node1  192.168.2.219 node2  192.168.2.220  kubeadm installall server in">
<meta name="keywords" content="k8s">
<meta property="og:type" content="article">
<meta property="og:title" content="k8s安装部署">
<meta property="og:url" content="http://abigfish.net/2022/05/10/k8s install/index.html">
<meta property="og:site_name" content="大鱼的博客">
<meta property="og:description" content="k8s install Kubernetes Cluster = N Master Node + N Worker Node：N主节点+N工作节点； N&amp;gt;=1  ready servercentos7 64  master 192.168.2.221 node1  192.168.2.219 node2  192.168.2.220  kubeadm installall server in">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2022-05-10T06:03:27.023Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="k8s安装部署">
<meta name="twitter:description" content="k8s install Kubernetes Cluster = N Master Node + N Worker Node：N主节点+N工作节点； N&amp;gt;=1  ready servercentos7 64  master 192.168.2.221 node1  192.168.2.219 node2  192.168.2.220  kubeadm installall server in">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://abigfish.net/2022/05/10/k8s install/">





  <title> k8s安装部署 | 大鱼的博客 </title>
</head>


<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">大鱼的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">bigfish's blog</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>
            
            站点地图
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocapitalize="off" autocomplete="off" autocorrect="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://abigfish.net/2022/05/10/k8s install/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="bigfish">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/photo.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="大鱼的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                k8s安装部署
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2022-05-10T10:48:39+08:00">
                2022-05-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/k8s/" itemprop="url" rel="index">
                    <span itemprop="name">k8s</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
              <span class="post-meta-divider">|</span>
              <span class="post-meta-item-icon">
                <i class="fa fa-comment-o"></i>
              </span>
              
                <a href="/2022/05/10/k8s install/#SOHUCS" itemprop="discussionUrl">
                  <span id="changyan_count_unit" class="post-comments-count hc-comment-count" data-xid="2022/05/10/k8s install/" itemprop="commentsCount"></span>
                </a>
              
            
          

          
          
             <span id="/2022/05/10/k8s install/" class="leancloud_visitors" data-flag-title="k8s安装部署">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">阅读次数 </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          

        </span></div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="k8s-install"><a href="/2022/05/10/k8s install/#k8s-install" class="headerlink" title="k8s install"></a>k8s install</h1><blockquote>
<p>Kubernetes Cluster = N Master Node + N Worker Node：N主节点+N工作节点； N&gt;=1</p>
</blockquote>
<h2 id="ready-server"><a href="/2022/05/10/k8s install/#ready-server" class="headerlink" title="ready server"></a>ready server</h2><p>centos7 64</p>
<ul>
<li>master 192.168.2.221</li>
<li>node1  192.168.2.219</li>
<li>node2  192.168.2.220</li>
</ul>
<h2 id="kubeadm-install"><a href="/2022/05/10/k8s install/#kubeadm-install" class="headerlink" title="kubeadm install"></a>kubeadm install</h2><p><em>all server install such as:</em></p>
<h3 id="base-setting"><a href="/2022/05/10/k8s install/#base-setting" class="headerlink" title="base setting"></a>base setting</h3><blockquote>
<p>1、setting hostname</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname master</span><br><span class="line">hostnamectl set-hostname node1</span><br><span class="line">hostnamectl set-hostname node2</span><br></pre></td></tr></table></figure>
<blockquote>
<p>2、setting selinux</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo setenforce 0</span><br><span class="line">sudo sed -i &apos;s/^SELINUX=enforcing$/SELINUX=permissive/&apos; /etc/selinux/config</span><br></pre></td></tr></table></figure>
<blockquote>
<p>3、turn off swap</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a  </span><br><span class="line">sed -ri &apos;s/.*swap.*/#&amp;/&apos; /etc/fstab</span><br></pre></td></tr></table></figure>
<blockquote>
<p>4、iptables could bridge</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/modules-load.d/k8s.conf</span><br><span class="line">br_netfilter</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF | sudo tee /etc/sysctl.d/k8s.conf</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<p>or do</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/sysctl.conf</span><br><span class="line"></span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line"># </span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>
<blockquote>
<p>5、install kubelet、kubeadm、kubectl</p>
<p>kubectl 是供程序员使用的命令行，一般只安装在mater(总部)。</p>
<p>kubeadm 帮助程序员管理集群 (如设置主节点并创建主节点中的控制平面的组件)。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">cat &lt;&lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo</span><br><span class="line">[kubernetes]</span><br><span class="line">name=Kubernetes</span><br><span class="line">baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64</span><br><span class="line">enabled=1</span><br><span class="line">gpgcheck=0</span><br><span class="line">repo_gpgcheck=0</span><br><span class="line">gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg</span><br><span class="line">   http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg</span><br><span class="line">exclude=kubelet kubeadm kubectl</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y kubelet-1.20.9 kubeadm-1.20.9 kubectl-1.20.9 --disableexcludes=kubernetes</span><br></pre></td></tr></table></figure>
<blockquote>
<p>6、start kubelet</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl enable --now kubelet</span><br><span class="line"># look at kubelet status</span><br><span class="line">systemctl status kubelet</span><br></pre></td></tr></table></figure>
<blockquote>
<p>7、use kubeadm to Cluster </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">sudo tee ./images.sh &lt;&lt;-&apos;EOF&apos;</span><br><span class="line">#!/bin/bash</span><br><span class="line">images=(</span><br><span class="line">kube-apiserver:v1.20.9</span><br><span class="line">kube-proxy:v1.20.9</span><br><span class="line">kube-controller-manager:v1.20.9</span><br><span class="line">kube-scheduler:v1.20.9</span><br><span class="line">coredns:1.7.0</span><br><span class="line">etcd:3.4.13-0</span><br><span class="line">pause:3.2</span><br><span class="line">)</span><br><span class="line">for imageName in $&#123;images[@]&#125; ; do</span><br><span class="line">docker pull registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/$imageName</span><br><span class="line">done</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chmod +x ./images.sh &amp;&amp; ./images.sh</span><br><span class="line"></span><br><span class="line">docker images</span><br></pre></td></tr></table></figure>
<p><em>finish install</em></p>
<p><strong>next copy vm to node1 node2</strong></p>
<blockquote>
<p>9、setting domain mapping to all vm(master,node1,node2)</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;192.168.2.221  cluster-endpoint&quot; &gt;&gt; /etc/hosts</span><br></pre></td></tr></table></figure>
<blockquote>
<p>10、init master</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubeadm init \</span><br><span class="line">--apiserver-advertise-address=192.168.2.221 \</span><br><span class="line">--control-plane-endpoint=cluster-endpoint \</span><br><span class="line">--image-repository registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images \</span><br><span class="line">--kubernetes-version v1.20.9 \</span><br><span class="line">--service-cidr=10.96.0.0/16 \</span><br><span class="line">--pod-network-cidr=172.31.0.0/16</span><br></pre></td></tr></table></figure>
<p><strong><code>-pod-network-cidr=172.31.0.0/16</code> 非常重要，用于为pod分配ip地址</strong></p>
<ul>
<li>初始化主节点成功,同时给出一系列<strong>提示</strong>（接下来按提示操作）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"># ...</span><br><span class="line"># 【翻译】你的Kubernetes控制平面已经成功初始化</span><br><span class="line">[init] Using Kubernetes version: v1.20.9</span><br><span class="line">[preflight] Running pre-flight checks</span><br><span class="line">        [WARNING Service-Docker]: docker service is not enabled, please run &apos;systemctl enable docker.service&apos;</span><br><span class="line">        [WARNING IsDockerSystemdCheck]: detected &quot;cgroupfs&quot; as the Docker cgroup driver. The recommended driver is &quot;systemd&quot;. Please follow the guide at https://kubernetes.io/docs/setup/cri/</span><br><span class="line">[preflight] Pulling images required for setting up a Kubernetes cluster</span><br><span class="line">[preflight] This might take a minute or two, depending on the speed of your internet connection</span><br><span class="line">[preflight] You can also perform this action in beforehand using &apos;kubeadm config images pull&apos;</span><br><span class="line">[certs] Using certificateDir folder &quot;/etc/kubernetes/pki&quot;</span><br><span class="line">[certs] Generating &quot;ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver&quot; certificate and key</span><br><span class="line">[certs] apiserver serving cert is signed for DNS names [centosdb cluster-endpoint kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 192.168.2.221]</span><br><span class="line">[certs] Generating &quot;apiserver-kubelet-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;front-proxy-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/ca&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;etcd/server&quot; certificate and key</span><br><span class="line">[certs] etcd/server serving cert is signed for DNS names [centosdb localhost] and IPs [192.168.2.221 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/peer&quot; certificate and key</span><br><span class="line">[certs] etcd/peer serving cert is signed for DNS names [centosdb localhost] and IPs [192.168.2.221 127.0.0.1 ::1]</span><br><span class="line">[certs] Generating &quot;etcd/healthcheck-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;apiserver-etcd-client&quot; certificate and key</span><br><span class="line">[certs] Generating &quot;sa&quot; key and public key</span><br><span class="line">[kubeconfig] Using kubeconfig folder &quot;/etc/kubernetes&quot;</span><br><span class="line">[kubeconfig] Writing &quot;admin.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;kubelet.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;controller-manager.conf&quot; kubeconfig file</span><br><span class="line">[kubeconfig] Writing &quot;scheduler.conf&quot; kubeconfig file</span><br><span class="line">[kubelet-start] Writing kubelet environment file with flags to file &quot;/var/lib/kubelet/kubeadm-flags.env&quot;</span><br><span class="line">[kubelet-start] Writing kubelet configuration to file &quot;/var/lib/kubelet/config.yaml&quot;</span><br><span class="line">[kubelet-start] Starting the kubelet</span><br><span class="line">[control-plane] Using manifest folder &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-apiserver&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-controller-manager&quot;</span><br><span class="line">[control-plane] Creating static Pod manifest for &quot;kube-scheduler&quot;</span><br><span class="line">[etcd] Creating static Pod manifest for local etcd in &quot;/etc/kubernetes/manifests&quot;</span><br><span class="line">[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory &quot;/etc/kubernetes/manifests&quot;. This can take up to 4m0s</span><br><span class="line">[apiclient] All control plane components are healthy after 16.003830 seconds</span><br><span class="line">[upload-config] Storing the configuration used in ConfigMap &quot;kubeadm-config&quot; in the &quot;kube-system&quot; Namespace</span><br><span class="line">[kubelet] Creating a ConfigMap &quot;kubelet-config-1.20&quot; in namespace kube-system with the configuration for the kubelets in the cluster</span><br><span class="line">[upload-certs] Skipping phase. Please see --upload-certs</span><br><span class="line">[mark-control-plane] Marking the node centosdb as control-plane by adding the labels &quot;node-role.kubernetes.io/master=&apos;&apos;&quot; and &quot;node-role.kubernetes.io/control-plane=&apos;&apos; (deprecated)&quot;</span><br><span class="line">[mark-control-plane] Marking the node centosdb as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]</span><br><span class="line">[bootstrap-token] Using token: xxxid4.qfgy66yoykp07cjw</span><br><span class="line">[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token</span><br><span class="line">[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster</span><br><span class="line">[bootstrap-token] Creating the &quot;cluster-info&quot; ConfigMap in the &quot;kube-public&quot; namespace</span><br><span class="line">[kubelet-finalize] Updating &quot;/etc/kubernetes/kubelet.conf&quot; to point to a rotatable kubelet client certificate and key</span><br><span class="line">[addons] Applied essential addon: CoreDNS</span><br><span class="line">[addons] Applied essential addon: kube-proxy</span><br><span class="line"></span><br><span class="line">Your Kubernetes control-plane has initialized successfully!</span><br><span class="line"></span><br><span class="line">To start using your cluster, you need to run the following as a regular user:</span><br><span class="line"></span><br><span class="line">  mkdir -p $HOME/.kube</span><br><span class="line">  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">  sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br><span class="line"></span><br><span class="line">Alternatively, if you are the root user, you can run:</span><br><span class="line"></span><br><span class="line">  export KUBECONFIG=/etc/kubernetes/admin.conf</span><br><span class="line"></span><br><span class="line">You should now deploy a pod network to the cluster.</span><br><span class="line">Run &quot;kubectl apply -f [podnetwork].yaml&quot; with one of the options listed at:</span><br><span class="line">  https://kubernetes.io/docs/concepts/cluster-administration/addons/</span><br><span class="line"></span><br><span class="line">You can now join any number of control-plane nodes by copying certificate authorities</span><br><span class="line">and service account keys on each node and then running the following as root:</span><br><span class="line"></span><br><span class="line">  kubeadm join cluster-endpoint:6443 --token xxxid4.qfgy66yoykp07cjw \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c00aaa55766bdfef9f92c04a1c7e8f871e9f270dc1619f47519ab6d3223e3450 \</span><br><span class="line">    --control-plane </span><br><span class="line"></span><br><span class="line">Then you can join any number of worker nodes by running the following on each as root:</span><br><span class="line"></span><br><span class="line">kubeadm join cluster-endpoint:6443 --token xxxid4.qfgy66yoykp07cjw \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c00aaa55766bdfef9f92c04a1c7e8f871e9f270dc1619f47519ab6d3223e3450</span><br></pre></td></tr></table></figure>
<blockquote>
<p>10、按照英文提示执行</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p $HOME/.kube</span><br><span class="line">sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config</span><br><span class="line">sudo chown $(id -u):$(id -g) $HOME/.kube/config</span><br></pre></td></tr></table></figure>
<blockquote>
<p>11、 look  at all nodes</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get nodes</span><br><span class="line">NAME        STATUS     ROLES                  AGE   VERSION</span><br><span class="line">master     Ready    control-plane,master   17h   v1.20.9</span><br></pre></td></tr></table></figure>
<h3 id="install-network-components-calico"><a href="/2022/05/10/k8s install/#install-network-components-calico" class="headerlink" title="install network components calico"></a>install network components calico</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl https://docs.projectcalico.org/manifests/calico.yaml -O</span><br><span class="line"></span><br><span class="line">kubectl apply -f calico.yaml</span><br></pre></td></tr></table></figure>
<p><em>修改 calico.yaml 配置，使网段同 <code>--pod-network-cidr=172.31.0.0/16</code> 一致，除非是192.168**就不用改</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim calico.yaml </span><br><span class="line">?192.168 #vim工具搜索</span><br><span class="line"></span><br><span class="line"># no effect. This should fall within `--cluster-cidr`.</span><br><span class="line">- name: CALICO_IPV4POOL_CIDR</span><br><span class="line">    value: &quot;172.31.0.0/16&quot;</span><br><span class="line"># Disable file logging so `kubectl logs` works.</span><br></pre></td></tr></table></figure>
<p><em>常用命令</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">#查看集群所有节点</span><br><span class="line">kubectl get nodes</span><br><span class="line"></span><br><span class="line">#根据配置文件，给集群创建资源</span><br><span class="line">kubectl apply -f xxxx.yaml</span><br><span class="line"></span><br><span class="line">#查看集群部署了哪些应用？</span><br><span class="line">docker ps   </span><br><span class="line"># 效果等于   </span><br><span class="line">kubectl get pods -A</span><br></pre></td></tr></table></figure>
<p><em>look at master status</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@centosdb ~]# kubectl get pods -A</span><br><span class="line">NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system            calico-kube-controllers-6fcb5c5bcf-q5mkg     1/1     Running   0          17h</span><br><span class="line">kube-system            calico-node-8fnpb                            0/1     Running   0          17h</span><br><span class="line">kube-system            calico-node-l49k6                            0/1     Running   0          17h</span><br><span class="line">kube-system            calico-node-q5pd6                            0/1     Running   0          17h</span><br><span class="line">kube-system            coredns-5897cd56c4-kqvxd                     1/1     Running   0          17h</span><br><span class="line">kube-system            coredns-5897cd56c4-zkxmz                     1/1     Running   0          17h</span><br><span class="line">kube-system            etcd-centosdb                                1/1     Running   0          17h</span><br><span class="line">kube-system            kube-apiserver-centosdb                      1/1     Running   0          17h</span><br><span class="line">kube-system            kube-controller-manager-centosdb             1/1     Running   0          17h</span><br><span class="line">kube-system            kube-proxy-87h9h                             1/1     Running   0          17h</span><br><span class="line">kube-system            kube-proxy-b8zxc                             1/1     Running   0          17h</span><br><span class="line">kube-system            kube-proxy-vlhcs                             1/1     Running   0          17h</span><br><span class="line">kube-system            kube-scheduler-centosdb                      1/1     Running   0          17h</span><br></pre></td></tr></table></figure>
<blockquote>
<p>将node1、node2 进入工作节点</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubeadm join cluster-endpoint:6443 --token xxxid4.qfgy66yoykp07cjw \</span><br><span class="line">    --discovery-token-ca-cert-hash sha256:c00aaa55766bdfef9f92c04a1c7e8f871e9f270dc1619f47519ab6d3223e3450</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@centosdb ~]# kubectl get nodes</span><br><span class="line">NAME         STATUS   ROLES                  AGE   VERSION</span><br><span class="line">node1   Ready    &lt;none&gt;                 17h   v1.20.9</span><br><span class="line">node2   Ready    &lt;none&gt;                 17h   v1.20.9</span><br><span class="line">master     Ready    control-plane,master   17h   v1.20.9</span><br></pre></td></tr></table></figure>
<h3 id="install-dashboard"><a href="/2022/05/10/k8s install/#install-dashboard" class="headerlink" title="install dashboard"></a>install dashboard</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.3.1/aio/deploy/recommended.yaml</span><br><span class="line"># or do</span><br><span class="line">kubectl apply -f recommended.yaml</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@centosdb ~]# kubectl get pods -A</span><br><span class="line">kubernetes-dashboard   dashboard-metrics-scraper-79c5968bdc-qrbzf   1/1     Running   0          16h</span><br><span class="line">kubernetes-dashboard   kubernetes-dashboard-7448ffc97b-64tf2        1/1     Running   0          16h</span><br></pre></td></tr></table></figure>
<blockquote>
<p>设置访问端口</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit svc kubernetes-dashboard -n kubernetes-dashboard</span><br></pre></td></tr></table></figure>
<p>提示: 进入文件将<code>type: ClusterIP</code>改为<code>type: NodePort</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get svc -A | grep kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">[root@centosdb ~]# kubectl get svc -A | grep kubernetes-dashboard</span><br><span class="line">kubernetes-dashboard   dashboard-metrics-scraper   ClusterIP   10.96.117.164   &lt;none&gt;        8000/TCP                 16h</span><br><span class="line">kubernetes-dashboard   kubernetes-dashboard        NodePort    10.96.181.30    &lt;none&gt;        443:30104/TCP            16h</span><br></pre></td></tr></table></figure>
<p><em><a href="https://192.168.2.219:30104" target="_blank" rel="noopener">https://192.168.2.219:30104</a></em></p>
<blockquote>
<p>setting dashboard accout </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">#vim dash.yaml</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kubernetes-dashboard</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f dash.yaml</span><br><span class="line"></span><br><span class="line"># generate dashboard token</span><br><span class="line"></span><br><span class="line">[root@centosdb ~]# kubectl -n kubernetes-dashboard get secret $(kubectl -n kubernetes-dashboard get sa/admin-user -o jsonpath=&quot;&#123;.secrets[0].name&#125;&quot;) -o go-template=&quot;&#123;&#123;.data.token | base64decode&#125;&#125;&quot;</span><br><span class="line">eyJhbGciOiJSUzI1NiIsImtpZCI6IndNSllNU3p0MzRJVDhoV0NWMEJqZkd5WmdveEpkcXExbEZmOHY1d21PUWcifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlcm5ldGVzLWRhc2hib2FyZCIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJhZG1pbi11c2VyLXRva2VuLXI4MnJiIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQubmFtZSI6ImFkbWluLXVzZXIiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC51aWQiOiI4ODQ3OWY5MC1jOTljLTQzNWYtYjkzMy04MWUwMDk5N2E0OWIiLCJzdWIiOiJzeXN0ZW06c2VydmljZWFjY291bnQ6a3ViZXJuZXRlcy1kYXNoYm9hcmQ6YWRtaW4tdXNlciJ9.YA23lwjuF3CW4pRYLOSFAPWeFtOQXNa7RPsz12v_twxOacvoZoZsxEpBJj0WO_TNSLk4luvHY4fhG3udfZxI_-IvJaPY667-C4AYENOIAQ1QCIU_Qo_NoyJCQ5WQfM_RpIsCng7X7dJy1sSs5UiceXFQfMDEfbUoSAZ4GViU_bXuloEaWkIfGl4c5RT_tuaDoDvHNjLRGUv_tQgpzAt6IZoZooLgsON1p0F9AIX8wJ-1c7BdvMa4quAvJ_eFgR65flLrfeWJH9lkz_gnz671jPqkVV_fRpL-H_767jHD1sKlS9wHqYVm-eu1p_gjISyPQUTdwrw72P7x_saMaG2XPA</span><br></pre></td></tr></table></figure>
<p>next login <em><a href="https://192.168.2.219:30104" target="_blank" rel="noopener">https://192.168.2.219:30104</a></em></p>
<p><strong>注：calico node不运行</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">kube-system            calico-node-8fnpb                            0/1     Running   0          17h</span><br><span class="line">kube-system            calico-node-l49k6                            0/1     Running   0          17h</span><br><span class="line">kube-system            calico-node-q5pd6                            0/1     Running   0          17h</span><br><span class="line"></span><br><span class="line">kubectl describe pod calico-node-8fnpb -n kube-system</span><br><span class="line"></span><br><span class="line">IRD: unable to connect to BIRDv4 socket: dial unix /var/run/calico/bird.ctl: connect: connection refused</span><br><span class="line">  Warning  Unhealthy  14m   kubelet            Readiness probe failed: 2022-05-07 03:01:44.179 [INFO][204] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:01:54.107 [INFO][243] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:02:04.112 [INFO][276] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:02:14.133 [INFO][317] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:02:24.106 [INFO][351] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:02:34.133 [INFO][385] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  13m  kubelet  Readiness probe failed: 2022-05-07 03:02:44.119 [INFO][426] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  12m  kubelet  Readiness probe failed: 2022-05-07 03:02:54.108 [INFO][458] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br><span class="line">  Warning  Unhealthy  4m12s (x52 over 12m)  kubelet  (combined from similar events): Readiness probe failed: 2022-05-07 03:11:34.318 [INFO][2258] confd/health.go 180: Number of node(s) with BGP peering established = 0</span><br><span class="line">calico/node is not ready: BIRD is not ready: BGP not established with 192.168.2.219,192.168.2.220</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">kubectl edit daemonset calico-node -n kube-system</span><br><span class="line">- name: CALICO_IPV4POOL_CIDR</span><br><span class="line">  value: 172.31.0.0/16</span><br><span class="line">- name: IP_AUTODETECTION_METHOD</span><br><span class="line">  value: interface=eth0</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -A</span><br><span class="line">NAMESPACE              NAME                                         READY   STATUS    RESTARTS   AGE</span><br><span class="line">kube-system            calico-node-bw8b9                            1/1     Running   0          35s</span><br><span class="line">kube-system            calico-node-g4dvb                            1/1     Running   0          50s</span><br><span class="line">kube-system            calico-node-tftp8                            1/1     Running   0          63s</span><br></pre></td></tr></table></figure>
<p><em>注意三台机必须相互能Ping得通</em></p>
<h3 id="namespace"><a href="/2022/05/10/k8s install/#namespace" class="headerlink" title="namespace"></a>namespace</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubectl create ns hello</span><br><span class="line">kubectl delete ns hello</span><br><span class="line"></span><br><span class="line"># vi creates.yaml</span><br><span class="line">apiVersion: v1 # 版本</span><br><span class="line">kind: Namespace # 类型</span><br><span class="line">metadata:</span><br><span class="line">  name: hello</span><br><span class="line"></span><br><span class="line">kubectl apply -f creates.yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p>运行Pod</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">kubectl run 【Pod名称】 --image=【镜像名称】</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl run mynginx --image=nginx</span><br><span class="line">pod/mynginx created</span><br><span class="line"></span><br><span class="line">[root@centosdb ~]# kubectl get pod</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE</span><br><span class="line">mynginx   1/1     Running   0          81s</span><br></pre></td></tr></table></figure>
<p><em>常用命令</em></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">#查看default名称空间的Pod</span><br><span class="line">kubectl get pod </span><br><span class="line">#描述</span><br><span class="line">kubectl describe pod 你自己的Pod名字</span><br><span class="line">#删除</span><br><span class="line">kubectl delete pod Pod名字</span><br><span class="line">#查看Pod的运行日志</span><br><span class="line">kubectl logs Pod名字</span><br><span class="line"></span><br><span class="line">#每个Pod-k8s都会分配一个ip</span><br><span class="line">kubectl get pod -owide</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pod -owide</span><br><span class="line">NAME      READY   STATUS    RESTARTS   AGE   IP               NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">mynginx   1/1     Running   0          27m   172.31.145.131   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line"></span><br><span class="line">#使用Pod的ip+pod里面运行容器的端口</span><br><span class="line">curl 172.31.145.131</span><br><span class="line"></span><br><span class="line">进入pod</span><br><span class="line">kubectl exec -ti [pod-name] -n &lt;your-namespace&gt; -- /bin/sh</span><br><span class="line">kubectl exec -ti mynginx -- /bin/sh</span><br></pre></td></tr></table></figure>
<h3 id="Deployment"><a href="/2022/05/10/k8s install/#Deployment" class="headerlink" title="Deployment"></a>Deployment</h3><blockquote>
<p>多副本</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create deployment my-dep --image=nginx --replicas=3</span><br></pre></td></tr></table></figure>
<p>deployment.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: my-dep-02</span><br><span class="line">  name: my-dep-02</span><br><span class="line">spec:</span><br><span class="line">  replicas: 3</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: my-dep-02</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: my-dep-02</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br></pre></td></tr></table></figure>
<blockquote>
<p>扩缩容</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl scale --replicas=5 deployment/my-dep</span><br><span class="line">kubectl edit deployment my-dep</span><br><span class="line"></span><br><span class="line">#修改replicas</span><br></pre></td></tr></table></figure>
<blockquote>
<p>滚动更新</p>
</blockquote>
<p>将一个pod集群在正常提供服务时从V1版本升级成 V2版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl set image deployment/my-dep-02 nginx=nginx:1.16.1 --record</span><br><span class="line">kubectl rollout status deployment/my-dep-02</span><br></pre></td></tr></table></figure>
<p>通过修改deployment配置文件实现更新</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit deployment/my-dep-02</span><br></pre></td></tr></table></figure>
<blockquote>
<p>版本回退</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl rollout history deployment/my-dep-02</span><br><span class="line">deployment.apps/my-dep-02 </span><br><span class="line">REVISION  CHANGE-CAUSE</span><br><span class="line">1         &lt;none&gt;</span><br><span class="line">2         &lt;none&gt;</span><br><span class="line">3         kubectl set image deployment/my-dep-02 nginx=nginx:1.16.1 --record=true</span><br></pre></td></tr></table></figure>
<p>查看某个历史详情</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout history deployment/my-dep-02 --revision=3</span><br></pre></td></tr></table></figure>
<p>回滚到上次的版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment/my-dep-02</span><br></pre></td></tr></table></figure>
<p>回滚到指定版本</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl rollout undo deployment/my-dep-02 --to-revision=1</span><br></pre></td></tr></table></figure>
<p>除了Deployment，k8s还有 <code>StatefulSet</code> 、<code>DaemonSet</code> 、<code>Job</code> 等 类型资源。我们都称为 <code>工作负载</code>。</p>
<p>有状态应用使用 <code>StatefulSet</code> 部署，无状态应用使用 <code>Deployment</code> 部署</p>
<h3 id="service"><a href="/2022/05/10/k8s install/#service" class="headerlink" title="service"></a>service</h3><p>以上内容的pod中的容器我们在外网都无法访问，使用Service来解决（–type=NodePort）。</p>
<blockquote>
<p>Service是 将一组 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pods</a> 公开为网络服务的抽象方法。</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get service</span><br><span class="line">NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1    &lt;none&gt;        443/TCP   21h</span><br></pre></td></tr></table></figure>
<blockquote>
<p>暴露deployment的服务和端口,进行端口映射，创建出具有ip地址的Service (pod的集群)</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment my-dep-02 --port=8000 --target-port=80</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get service</span><br><span class="line">NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP    22h</span><br><span class="line">my-dep-02    ClusterIP   10.96.226.142   &lt;none&gt;        8000/TCP   4s</span><br></pre></td></tr></table></figure>
<blockquote>
<p>查看pod的标签</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod --show-labels</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pod --show-labels</span><br><span class="line">NAME                         READY   STATUS    RESTARTS   AGE     LABELS</span><br><span class="line">my-dep-02-7b9d6bb69c-4fvl8   1/1     Running   0          5m31s   app=my-dep-02,pod-template-hash=7b9d6bb69c</span><br><span class="line">my-dep-02-7b9d6bb69c-j4mjk   1/1     Running   0          5m31s   app=my-dep-02,pod-template-hash=7b9d6bb69c</span><br><span class="line">my-dep-02-7b9d6bb69c-k7lhl   1/1     Running   0          5m31s   app=my-dep-02,pod-template-hash=7b9d6bb69c</span><br><span class="line">mynginx                      1/1     Running   0          157m    run=mynginx</span><br><span class="line">#使用标签检索Pod</span><br><span class="line">kubectl get pod -l app=my-dep-02</span><br></pre></td></tr></table></figure>
<blockquote>
<p>查看service/my-dep-02 的yaml配置文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get service/my-dep-02 -o yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p>重里面pod访问</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl exec -ti my-dep-02-7b9d6bb69c-4fvl8 -- /bin/sh</span><br><span class="line"># curl my-dep-02.default.svc:8000</span><br></pre></td></tr></table></figure>
<blockquote>
<p>删除Service</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete service/my-dep-02</span><br></pre></td></tr></table></figure>
<blockquote>
<p>clusterIP</p>
</blockquote>
<ul>
<li>默认就是ClusterIP 等同于没有–type的</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment my-dep-02 --port=8000 --target-port=80 --type=ClusterIP</span><br></pre></td></tr></table></figure>
<blockquote>
<p>NodePort</p>
</blockquote>
<ul>
<li>集群外可以访问</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl expose deployment my-dep-02 --port=8000 --target-port=80 --type=NodePort</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get service</span><br><span class="line">NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kubernetes   ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          22h</span><br><span class="line">my-dep-02    NodePort    10.96.200.109   &lt;none&gt;        8000:30037/TCP   10s</span><br></pre></td></tr></table></figure>
<p> <strong>ip+port映射</strong>: 集群外<code>（mater、node1、node2的ip):30037</code> 映射到 <code>10.96.200.109:8000</code></p>
<p>外网访问 可以 <a href="http://192.168.2.219:30037" target="_blank" rel="noopener">http://192.168.2.219:30037</a></p>
<h3 id="Ingress-网关"><a href="/2022/05/10/k8s install/#Ingress-网关" class="headerlink" title="Ingress(网关)"></a>Ingress(网关)</h3><blockquote>
<p>Ingress：Service的统一网关入口（如百度的统一域名访问，统一Service层），Ingress是k8s机器集群的统一入口，请求流量先经过Ingress（入口）再进入集群内接受服务。</p>
<p> service是为一组pod服务提供一个统一集群内访问入口或外部访问的随机端口，而ingress做得是通过反射的形式对服务进行分发到对应的service上。</p>
<p>service一般是针对内部的，集群内部调用，而ingress应该是针对外部调用的</p>
<p>service只是开了端口，可以通过服务器IP:端口的方式去访问，但是服务器IP还是可变的，Ingress应该就是作为网关去转发</p>
<p>因为有很多服务,入口不统一,不方便管理</p>
</blockquote>
<blockquote>
<p>安装ingress</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://github.com/kubernetes/ingress-nginx/blob/controller-v0.47.0/deploy/static/provider/baremetal/deploy.yaml</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi deploy.yaml</span><br><span class="line">#将image的值改为如下值：</span><br><span class="line">registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/ingress-nginx-controller:v0.46.0</span><br><span class="line"></span><br><span class="line">kubectl apply -f deploy.yaml</span><br></pre></td></tr></table></figure>
<blockquote>
<p>查看安装结果</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod,svc -n ingress-nginx</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get pod,svc -n ingress-nginx</span><br><span class="line">NAME                                            READY   STATUS              RESTARTS   AGE</span><br><span class="line">pod/ingress-nginx-admission-create-j92kq        0/1     Completed           0          2m27s</span><br><span class="line">pod/ingress-nginx-admission-patch-2pmwz         0/1     Completed           2          2m27s</span><br><span class="line">pod/ingress-nginx-controller-65bf56f7fc-8b4nk   0/1     ContainerCreating   0          2m27s</span><br></pre></td></tr></table></figure>
<ul>
<li>新建了Service，以NodePort方式暴露了端口</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl get service -A | grep ingress</span><br><span class="line">ingress-nginx          ingress-nginx-controller             NodePort    10.96.160.237   &lt;none&gt;        80:32335/TCP,443:30536/TCP   3m29s</span><br><span class="line">ingress-nginx          ingress-nginx-controller-admission   ClusterIP   10.96.138.149   &lt;none&gt;        443/TCP                      3m29s</span><br></pre></td></tr></table></figure>
<p>映射：32335,30536</p>
<p><a href="http://192.168.2.221:30536/，bad" target="_blank" rel="noopener">http://192.168.2.221:30536/，bad</a> request</p>
<p><a href="http://192.168.2.221:32335" target="_blank" rel="noopener">http://192.168.2.221:32335</a> , notfound</p>
<ul>
<li>安装测试环境</li>
</ul>
<blockquote>
<p>应用配置文件，部署了2个Deployment,2个Service</p>
</blockquote>
<p>ingresstest.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: hello-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: hello-server</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: hello-server</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9000</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  name: nginx-demo</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: nginx-demo</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 80</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: hello-server</span><br><span class="line">  name: hello-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    app: hello-server</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8000</span><br><span class="line">    protocol: TCP</span><br><span class="line">    targetPort: 9000</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f ingresstest.yaml </span><br><span class="line">deployment.apps/hello-server created</span><br><span class="line">deployment.apps/nginx-demo created</span><br><span class="line">service/nginx-demo created</span><br><span class="line">service/hello-server created</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get service</span><br><span class="line">NAME           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">hello-server   ClusterIP   10.96.121.161   &lt;none&gt;        8000/TCP         69s</span><br><span class="line">kubernetes     ClusterIP   10.96.0.1       &lt;none&gt;        443/TCP          22h</span><br><span class="line">my-dep-02      NodePort    10.96.200.109   &lt;none&gt;        8000:30037/TCP   30m</span><br><span class="line">nginx-demo     ClusterIP   10.96.221.97    &lt;none&gt;        8000/TCP         69s</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get deployment -o wide</span><br><span class="line">NAME           READY   UP-TO-DATE   AVAILABLE   AGE     CONTAINERS     IMAGES                                                          SELECTOR</span><br><span class="line">hello-server   2/2     2            2           2m48s   hello-server   registry.cn-hangzhou.aliyuncs.com/lfy_k8s_images/hello-server   app=hello-server</span><br><span class="line">my-dep-02      3/3     3            3           55m     nginx          nginx                                                           app=my-dep-02</span><br><span class="line">nginx-demo     2/2     2            2           2m48s   nginx          nginx                                                           app=nginx-demo</span><br><span class="line"></span><br><span class="line">[root@master ~]#  kubectl get pods -o wide</span><br><span class="line">NAME                            READY   STATUS    RESTARTS   AGE     IP               NODE         NOMINATED NODE   READINESS GATES</span><br><span class="line">hello-server-6cbb679d85-5t2t4   1/1     Running   0          3m34s   172.31.145.140   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">hello-server-6cbb679d85-88ndh   1/1     Running   0          3m34s   172.31.145.139   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">my-dep-02-7b9d6bb69c-4fvl8      1/1     Running   0          56m     172.31.145.136   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">my-dep-02-7b9d6bb69c-j4mjk      1/1     Running   0          56m     172.31.19.198    centosapp2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">my-dep-02-7b9d6bb69c-k7lhl      1/1     Running   0          56m     172.31.145.137   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">mynginx                         1/1     Running   0          3h28m   172.31.145.131   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-demo-7d56b74b84-rkjcd     1/1     Running   0          3m34s   172.31.19.202    centosapp2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-demo-7d56b74b84-twfms     1/1     Running   0          3m34s   172.31.19.201    centosapp2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>域名访问</p>
</blockquote>
<ul>
<li>访问 hello.test.com 的请求由 hello-server (Service)集群处理</li>
<li>访问 demo.test.com 的请求由 nginx-demo (Service)集群处理</li>
<li>Ingress(网关)根据请求的域名分配对应的Service去处理</li>
</ul>
<p>ingresscom.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  # 类型</span><br><span class="line">metadata:</span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.test.com&quot; #域名</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix # 前缀</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server # Service 名称</span><br><span class="line">            port:</span><br><span class="line">              number: 8000 # 端口</span><br><span class="line">  - host: &quot;demo.test.com&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx&quot;  # 把请求会转给下面的service，下面的service一定要能处理这个路径，不能处理就是404</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo  # java，比如使用路径重写，去掉前缀nginx</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f ingresscom.yaml </span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar created</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get ingress</span><br><span class="line">NAME               CLASS   HOSTS                          ADDRESS         PORTS   AGE</span><br><span class="line">ingress-host-bar   nginx   hello.test.com,demo.test.com   192.168.2.220   80      2m47s</span><br></pre></td></tr></table></figure>
<ul>
<li>windows 配置域名映射（域名映射文件地址：<code>C:\Windows\System32\drivers\etc</code>）</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">192.168.2.220 hello.test.com </span><br><span class="line">192.168.2.220 demo.test.com</span><br></pre></td></tr></table></figure>
<p>浏览器：<a href="http://hello.test.com:32335/" target="_blank" rel="noopener">http://hello.test.com:32335/</a></p>
<p>hello world!</p>
<p>浏览器：<a href="http://demo.test.com:30536/" target="_blank" rel="noopener">http://demo.test.com:30536/</a>  nginx是由Ingress层返回的</p>
<p>400 bad request</p>
<p>nginx</p>
<ul>
<li>修改Ingress配置文件,将<code>path: &quot;/nginx&quot;</code>改成<code>path: &quot;/nginx.html&quot;</code></li>
</ul>
<p>浏览器：<a href="http://demo.test.com:32335/nginx.html" target="_blank" rel="noopener">http://demo.test.com:32335/nginx.html</a></p>
<p>404 not found</p>
<p>nginx/1.21.5</p>
<p>问题： path: “/nginx.html” 与 path: “/” 为什么会有不同的效果？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit ingress ingress-host-bar</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>修改配置文件 ingresscom.yaml</li>
</ul>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: networking.k8s.io/v1</span><br><span class="line">kind: Ingress  </span><br><span class="line">metadata:</span><br><span class="line">  annotations: # 路径重写配置功能开启</span><br><span class="line">    nginx.ingress.kubernetes.io/rewrite-target: /$2 </span><br><span class="line">  name: ingress-host-bar</span><br><span class="line">spec:</span><br><span class="line">  ingressClassName: nginx</span><br><span class="line">  rules:</span><br><span class="line">  - host: &quot;hello.test.com&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/&quot;</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: hello-server</span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br><span class="line">  - host: &quot;demo.test.com&quot;</span><br><span class="line">    http:</span><br><span class="line">      paths:</span><br><span class="line">      - pathType: Prefix</span><br><span class="line">        path: &quot;/nginx(/|$)(.*)&quot;  # 配置忽略/nginx</span><br><span class="line">        backend:</span><br><span class="line">          service:</span><br><span class="line">            name: nginx-demo </span><br><span class="line">            port:</span><br><span class="line">              number: 8000</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f ingresscom.yaml </span><br><span class="line">ingress.networking.k8s.io/ingress-host-bar configured</span><br></pre></td></tr></table></figure>
<p><a href="http://demo.test.com:32335/nginx.html" target="_blank" rel="noopener">http://demo.test.com:32335/nginx.html</a></p>
<p><a href="http://demo.test.com:32335" target="_blank" rel="noopener">http://demo.test.com:32335</a></p>
<p>都返回</p>
<p>404 not found</p>
<p>nginx</p>
<h3 id="存储抽象"><a href="/2022/05/10/k8s install/#存储抽象" class="headerlink" title="存储抽象"></a>存储抽象</h3><blockquote>
<p>所有节点都安装nfs</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y nfs-utils</span><br></pre></td></tr></table></figure>
<blockquote>
<p>nfs主节点</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;/nfs/data/ *(insecure,rw,sync,no_root_squash)&quot; &gt; /etc/exports</span><br><span class="line"></span><br><span class="line">mkdir -p /nfs/data</span><br><span class="line">systemctl enable rpcbind --now</span><br><span class="line">systemctl enable nfs-server --now</span><br><span class="line">#配置生效</span><br><span class="line">exportfs -r</span><br><span class="line"></span><br><span class="line">[root@master ~]# exportfs</span><br><span class="line">/nfs/data       &lt;world&gt;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>从节点</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">showmount -e 192.168.2.221</span><br><span class="line">[root@node1 ~]# showmount -e 192.168.2.221</span><br><span class="line">Export list for 192.168.2.221:</span><br><span class="line">/nfs/data *</span><br><span class="line"></span><br><span class="line">#执行以下命令挂载nfs服务器上的共享目录到本机路径/root/nfsmount</span><br><span class="line">mkdir -p /nfs/data</span><br><span class="line"></span><br><span class="line">mount -t nfs 192.168.2.221:/nfs/data /nfs/data</span><br><span class="line">#写入一个测试文件</span><br><span class="line">echo &quot;hello nfs server&quot; &gt; /nfs/data/test.txt</span><br></pre></td></tr></table></figure>
<p>在其它服务器查看test.txt</p>
<h4 id="nfs（原生）方式数据挂载"><a href="/2022/05/10/k8s install/#nfs（原生）方式数据挂载" class="headerlink" title="nfs（原生）方式数据挂载"></a>nfs（原生）方式数据挂载</h4><p>在所有服务器创建目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /nfs/data/nginx-pv/</span><br></pre></td></tr></table></figure>
<p>mountnfs.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-pv-demo</span><br><span class="line">  name: nginx-pv-demo</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2 </span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-pv-demo</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-pv-demo</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: html</span><br><span class="line">          mountPath: /usr/share/nginx/html</span><br><span class="line">      volumes:</span><br><span class="line">        - name: html</span><br><span class="line">          nfs:</span><br><span class="line">            server: 192.168.2.221</span><br><span class="line">            path: /nfs/data/nginx-pv/</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f mountnfs.yaml</span><br><span class="line">cd /nfs/data/nginx-pv/</span><br><span class="line">echo &quot;Hello Mount&quot; &gt; index.html</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -o wide</span><br><span class="line"></span><br><span class="line">nginx-pv-demo-587489dfcf-ljwqr   1/1     Running   0          85s     172.31.145.141   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-pv-demo-587489dfcf-ssc2c   1/1     Running   0          85s     172.31.19.203    centosapp2   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# curl 172.31.19.203</span><br><span class="line">Hello Mount</span><br></pre></td></tr></table></figure>
<h4 id="PV-持久卷-和PVC-持久卷申明"><a href="/2022/05/10/k8s install/#PV-持久卷-和PVC-持久卷申明" class="headerlink" title="PV(持久卷)和PVC(持久卷申明)"></a>PV(持久卷)和PVC(持久卷申明)</h4><p>NFS(原生)方式数据挂载存在一些问题：</p>
<ul>
<li>目录要自己创建</li>
<li>Deployment及其pod删除后,服务器目录数据依旧存在</li>
<li>挂载容量没有限制</li>
</ul>
<p>PV：持久卷（Persistent Volume），将应用需要持久化的数据保存到指定位置（存放持久化数据的目录就是持久卷）</p>
<p> PVC：持久卷申明（Persistent Volume Claim），申明需要使用的持久卷规格 （申请持久卷的申请书）</p>
<p>静态供应： 提取指定位置和空间大小</p>
<p>动态供应：位置和空间大小由pv自动创建</p>
<blockquote>
<p>创建pv池</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">在master</span><br><span class="line">mkdir -p /nfs/data/01</span><br><span class="line">mkdir -p /nfs/data/02</span><br><span class="line">mkdir -p /nfs/data/03</span><br></pre></td></tr></table></figure>
<p>创建三个 PV（持久卷）<strong>静态供应的方式</strong>，配置文件createPV.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume # 类型</span><br><span class="line">metadata:</span><br><span class="line">  name: pv01-10m # 名称</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 10M # 持久卷空间大小</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany # 多节点可读可写</span><br><span class="line">  storageClassName: nfs # 存储类名</span><br><span class="line">  nfs:</span><br><span class="line">    path: /nfs/data/01 # pc目录位置</span><br><span class="line">    server: 192.168.2.221</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv02-1gi</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 1Gi # 持久卷空间大小</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  storageClassName: nfs</span><br><span class="line">  nfs:</span><br><span class="line">    path: /nfs/data/02 # pc目录位置</span><br><span class="line">    server: 192.168.2.221</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: PersistentVolume</span><br><span class="line">metadata:</span><br><span class="line">  name: pv03-3gi</span><br><span class="line">spec:</span><br><span class="line">  capacity:</span><br><span class="line">    storage: 3Gi # 持久卷空间大小</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  storageClassName: nfs</span><br><span class="line">  nfs:</span><br><span class="line">    path: /nfs/data/03 # pc目录位置</span><br><span class="line">    server: 192.168.2.221</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f createPV.yaml</span><br><span class="line">persistentvolume/pv01-10m created</span><br><span class="line">persistentvolume/pv02-1gi created</span><br><span class="line">persistentvolume/pv03-3gi created</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get persistentvolume</span><br><span class="line">NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE</span><br><span class="line">pv01-10m   10M        RWX            Retain           Available           nfs                     48s</span><br><span class="line">pv02-1gi   1Gi        RWX            Retain           Available           nfs                     48s</span><br><span class="line">pv03-3gi   3Gi        RWX            Retain           Available           nfs                     48s</span><br></pre></td></tr></table></figure>
<blockquote>
<p>创建PVC</p>
</blockquote>
<p>createPVC.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">kind: PersistentVolumeClaim # 类型</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-pvc # PVC名称</span><br><span class="line">spec:</span><br><span class="line">  accessModes:</span><br><span class="line">    - ReadWriteMany</span><br><span class="line">  resources:</span><br><span class="line">    requests:</span><br><span class="line">      storage: 200Mi # 需要空间</span><br><span class="line">  storageClassName: nfs # 要对应PV的storageClassName</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f createPVC.yaml </span><br><span class="line">persistentvolumeclaim/nginx-pvc created</span><br><span class="line">[root@master ~]# kubectl get persistentvolumeclaim</span><br><span class="line">NAME        STATUS   VOLUME     CAPACITY   ACCESS MODES   STORAGECLASS   AGE</span><br><span class="line">nginx-pvc   Bound    pv02-1gi   1Gi        RWX            nfs            30s</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#查看PC,状态Bound(绑定),说明已经被使用,绑定信息： default/nginx-pvc =&gt; 名称空间/PVC名称</span><br><span class="line">[root@master ~]# kubectl get pv</span><br><span class="line">NAME       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM               STORAGECLASS   REASON   AGE</span><br><span class="line">pv01-10m   10M        RWX            Retain           Available                       nfs                     4m47s</span><br><span class="line">pv02-1gi   1Gi        RWX            Retain           Bound       default/nginx-pvc   nfs                     4m47s</span><br><span class="line">pv03-3gi   3Gi        RWX            Retain           Available                       nfs                     4m47s</span><br></pre></td></tr></table></figure>
<blockquote>
<p>创建Deployment ，让Deployment中的Pod绑定PVC</p>
</blockquote>
<p>boundPVC.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: nginx-deploy-pvc # Deployment名称</span><br><span class="line">  name: nginx-deploy-pvc</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2 # pod数量</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx-deploy-pvc</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx-deploy-pvc</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - image: nginx</span><br><span class="line">        name: nginx</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: html</span><br><span class="line">          mountPath: /usr/share/nginx/html # 挂载目录</span><br><span class="line">      volumes:</span><br><span class="line">        - name: html</span><br><span class="line">          persistentVolumeClaim:</span><br><span class="line">            claimName: nginx-pvc  # pvc 的名称</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]#  kubectl apply -f boundPVC.yaml</span><br><span class="line">deployment.apps/nginx-deploy-pvc created</span><br></pre></td></tr></table></figure>
<blockquote>
<p>向挂载目录 <code>/nfs/data/02</code>写入测试文件</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# cd /nfs/data/02</span><br><span class="line">[root@master 02]# echo &quot;boundPVC test nginx&quot; &gt; index.html</span><br><span class="line"></span><br><span class="line">[root@master 02]# kubectl get pod -o wide</span><br><span class="line">nginx-deploy-pvc-79fc8558c7-8m9nn   1/1     Running   0          97s     172.31.19.204    centosapp2   &lt;none&gt;           &lt;none&gt;</span><br><span class="line">nginx-deploy-pvc-79fc8558c7-s97vh   1/1     Running   0          97s     172.31.145.142   centosapp1   &lt;none&gt;           &lt;none&gt;</span><br></pre></td></tr></table></figure>
<h4 id="configMap-配置集"><a href="/2022/05/10/k8s install/#configMap-配置集" class="headerlink" title="configMap(配置集)"></a>configMap(配置集)</h4><p>ConfigMap 缩写为cm</p>
<p>ConfigMap（配置集）：用于配置文件挂载，抽取应用配置，并且可以自动更新。</p>
<blockquote>
<p>redis.conf内容如下：</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl create configmap redis-conf --from-file=redis.conf</span><br><span class="line">configmap/redis-conf created</span><br><span class="line"></span><br><span class="line">[root@master ~]# kubectl get configmap</span><br><span class="line">NAME               DATA   AGE</span><br><span class="line">kube-root-ca.crt   1      24h</span><br><span class="line">redis-conf         1      76s</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get configmap redis-conf -o yaml</span><br></pre></td></tr></table></figure>
<p>创建redistest.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod # 类型</span><br><span class="line">metadata:</span><br><span class="line">  name: redis # pod名称</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: redis</span><br><span class="line">    image: redis # 镜像</span><br><span class="line">    command:</span><br><span class="line">      - redis-server</span><br><span class="line">      - &quot;/redis-master/redis.conf&quot;  #指的是redis容器内部的位置</span><br><span class="line">    ports:</span><br><span class="line">    - containerPort: 6379 </span><br><span class="line">    volumeMounts: # 配置卷挂载</span><br><span class="line">    - mountPath: /data </span><br><span class="line">      name: data 	# 卷挂载名称  对应 下面的 挂载卷 data</span><br><span class="line">    - mountPath: /redis-master</span><br><span class="line">      name: config	 # 卷挂载名称  对应 下面的 挂载卷 config</span><br><span class="line">  volumes: # 挂载卷</span><br><span class="line">    - name: data </span><br><span class="line">      emptyDir: &#123;&#125; </span><br><span class="line">    - name: config </span><br><span class="line">      configMap:   # 配置集</span><br><span class="line">        name: redis-conf</span><br><span class="line">        items:</span><br><span class="line">        - key: redis.conf</span><br><span class="line">          path: redis.conf</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@master ~]# kubectl apply -f redistest.yaml </span><br><span class="line">pod/redis created</span><br><span class="line"></span><br><span class="line">kubectl exec -ti redis -- /bin/sh</span><br><span class="line">cd ../redis-manager</span><br><span class="line">more redis.conf</span><br><span class="line">appendonly yes</span><br></pre></td></tr></table></figure>
<p>修改配置集的redis.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl edit configmap redis-conf</span><br></pre></td></tr></table></figure>
<p>加入：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requirepass 123456</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@centosdb ~]# kubectl exec -ti redis -- /bin/sh</span><br><span class="line"># cd ../</span><br><span class="line"># ls</span><br><span class="line">bin   data  etc   lib    media  opt   redis-master  run   srv  tmp  var</span><br><span class="line">boot  dev   home  lib64  mnt    proc  root          sbin  sys  usr</span><br><span class="line"># cd redis-master</span><br><span class="line"># more redis.conf</span><br><span class="line">appendonly yes</span><br><span class="line">requirepass 123456</span><br></pre></td></tr></table></figure>
<h4 id="secret"><a href="/2022/05/10/k8s install/#secret" class="headerlink" title="secret"></a>secret</h4><p> Secret 对象类型<strong>用来保存敏感信息</strong>，例如密码、OAuth 令牌和 SSH 密钥。 将这些信息放在 secret 中比放在 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener">Pod</a> 的定义或者 <a href="https://kubernetes.io/zh/docs/reference/glossary/?all=true#term-image" target="_blank" rel="noopener">容器镜像</a> 中来说更加安全和灵活。原理同ConfigMap</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl create secret docker-registry 【Secret的名称】 \</span><br><span class="line">  --docker-server=【你的镜像仓库服务器】 \</span><br><span class="line">  --docker-username=【你的用户名】 \</span><br><span class="line">  --docker-password=【你的密码】 \</span><br><span class="line">  --docker-email=【你的邮箱地址】</span><br></pre></td></tr></table></figure>
<p>secret01.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: private-nginx # pod 名称</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: private-nginx</span><br><span class="line">    image: dockerywl/mysql # 私有镜像名称</span><br></pre></td></tr></table></figure>
<p>查看</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get secret</span><br></pre></td></tr></table></figure>
<p><em>来源：<a href="https://blog.csdn.net/weixin_46703850/article/details/122922090" target="_blank" rel="noopener">https://blog.csdn.net/weixin_46703850/article/details/122922090</a></em></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <ul class="post-copyright">
    <li class="post-copyright-author">
      <strong>本文作者：</strong>
      bigfish
    </li>
    <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="http://abigfish.net/2022/05/10/k8s install/" title="k8s安装部署">http://abigfish.net/2022/05/10/k8s install/</a>
    </li>
    <li class="post-copyright-license">
      <strong>版权声明： </strong>
      本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
    </li>
  </ul>


      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/k8s/" rel="tag"># k8s</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2022/05/01/docker install postgresql/" rel="next" title="docker安装postgresql">
                <i class="fa fa-chevron-left"></i> docker安装postgresql
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2022/05/10/k8s kubesphere/" rel="prev" title="k8s安装kubesphere">
                k8s安装kubesphere <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <!--MOB SHARE BEGIN-->
<div class="-mob-share-ui-button -mob-share-open">分享</div>
<div class="-mob-share-ui" style="display: none">
    <ul class="-mob-share-list">
        <li class="-mob-share-weibo"><p>新浪微博</p></li>
        <li class="-mob-share-tencentweibo"><p>腾讯微博</p></li>
        <li class="-mob-share-qzone"><p>QQ空间</p></li>
        <li class="-mob-share-qq"><p>QQ好友</p></li>
        <li class="-mob-share-renren"><p>人人网</p></li>
        <li class="-mob-share-kaixin"><p>开心网</p></li>
        <li class="-mob-share-douban"><p>豆瓣</p></li>
        <li class="-mob-share-facebook"><p>Facebook</p></li>
        <li class="-mob-share-twitter"><p>Twitter</p></li>
    </ul>
    <div class="-mob-share-close">取消</div>
</div>
<div class="-mob-share-ui-bg"></div>
<script id="-mob-share" src="https://f1.webshare.mob.com/code/mob-share.js?appkey=1ccac48aa5a00"></script>

      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="SOHUCS"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image" src="/images/photo.jpg" alt="bigfish">
          <p class="site-author-name" itemprop="name">bigfish</p>
           
              <p class="site-description motion-element" itemprop="description">record my life</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">81</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">34</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">42</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#k8s-install"><span class="nav-number">1.</span> <span class="nav-text">k8s install</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ready-server"><span class="nav-number">1.1.</span> <span class="nav-text">ready server</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kubeadm-install"><span class="nav-number">1.2.</span> <span class="nav-text">kubeadm install</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#base-setting"><span class="nav-number">1.2.1.</span> <span class="nav-text">base setting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#install-network-components-calico"><span class="nav-number">1.2.2.</span> <span class="nav-text">install network components calico</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#install-dashboard"><span class="nav-number">1.2.3.</span> <span class="nav-text">install dashboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#namespace"><span class="nav-number">1.2.4.</span> <span class="nav-text">namespace</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Deployment"><span class="nav-number">1.2.5.</span> <span class="nav-text">Deployment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#service"><span class="nav-number">1.2.6.</span> <span class="nav-text">service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ingress-网关"><span class="nav-number">1.2.7.</span> <span class="nav-text">Ingress(网关)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#存储抽象"><span class="nav-number">1.2.8.</span> <span class="nav-text">存储抽象</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#nfs（原生）方式数据挂载"><span class="nav-number">1.2.8.1.</span> <span class="nav-text">nfs（原生）方式数据挂载</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#PV-持久卷-和PVC-持久卷申明"><span class="nav-number">1.2.8.2.</span> <span class="nav-text">PV(持久卷)和PVC(持久卷申明)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#configMap-配置集"><span class="nav-number">1.2.8.3.</span> <span class="nav-text">configMap(配置集)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#secret"><span class="nav-number">1.2.8.4.</span> <span class="nav-text">secret</span></a></li></ol></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bigfish</span>
  <span id="busuanzi_container_site_uv">
  本站访问次数：<span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
  </span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  




	





  





  





  




  
    <script type="text/javascript">
    (function(){
      var appid = 'cyu62R7Sk';
      var conf = '1ddb5cdb2e688908ef5cc060ea346a6b';
      var width = window.innerWidth || document.documentElement.clientWidth;
      if (width < 960) {
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>'); } else { var loadJs=function(d,a){var c=document.getElementsByTagName("head")[0]||document.head||document.documentElement;var b=document.createElement("script");b.setAttribute("type","text/javascript");b.setAttribute("charset","UTF-8");b.setAttribute("src",d);if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}c.appendChild(b)};loadJs("https://changyan.sohu.com/upload/changyan.js",function(){
        window.changyan.api.config({appid:appid,conf:conf})});
      }
    })();
    </script>
    <script type="text/javascript" src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script>
  



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
      search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.popup').toggle();
    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';
      $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = $( "entry", xmlResponse ).map(function() {
            return {
              title: $( "title", this ).text(),
              content: $("content",this).text(),
              url: $( "url" , this).text()
            };
          }).get();
          var $input = document.getElementById(search_id);
          var $resultContent = document.getElementById(content_id);
          $input.addEventListener('input', function(){
            var matchcounts = 0;
            var str='<ul class=\"search-result-list\">';
            var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
            $resultContent.innerHTML = "";
            if (this.value.trim().length > 1) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var content_index = [];
                var data_title = data.title.trim().toLowerCase();
                var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                var data_url = decodeURIComponent(data.url);
                var index_title = -1;
                var index_content = -1;
                var first_occur = -1;
                // only match artiles with not empty titles and contents
                if(data_title != '') {
                  keywords.forEach(function(keyword, i) {
                    index_title = data_title.indexOf(keyword);
                    index_content = data_content.indexOf(keyword);
                    if( index_title >= 0 || index_content >= 0 ){
                      isMatch = true;
                      if (i == 0) {
                        first_occur = index_content;
                      }
                    }

                  });
                }
                // show search results
                if (isMatch) {
                  matchcounts += 1;
                  str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                  var content = data.content.trim().replace(/<[^>]+>/g,"");
                  if (first_occur >= 0) {
                    // cut out 100 characters
                    var start = first_occur - 20;
                    var end = first_occur + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if(start == 0){
                      end = 50;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    var match_content = content.substring(start, end);
                    // highlight all keywords
                    keywords.forEach(function(keyword){
                      var regS = new RegExp(keyword, "gi");
                      match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                    });

                    str += "<p class=\"search-result\">" + match_content +"...</p>"
                  }
                  str += "</li>";
                }
              })};
            str += "</ul>";
            if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
            if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
            $resultContent.innerHTML = str;
          });
          proceedsearch();
        }
      });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("K6CpIXEyvcJ8rtkxMu0gBjmR-gzGzoHsz", "Cre2YXPrOsbcFrloqDEYr7F0");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  

  



</body>
</html>
